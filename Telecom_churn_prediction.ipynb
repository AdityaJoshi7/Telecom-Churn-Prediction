{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2864919c-9b4c-4dc4-9a6a-caa6a9fdb9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04a1e62c-b2e8-468d-8143-3125b7fffd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Training Data\n",
    "\n",
    "train_data = pd.read_csv(\"Customer_Data.csv\")\n",
    "\n",
    "# Map actual statuses to 0 (not churned) / 1 (churned)\n",
    "status_map = {\n",
    "    'Stayed': 0,\n",
    "    'Joined': 0,\n",
    "    'Churned': 1\n",
    "}\n",
    "train_data['Customer_Status'] = train_data['Customer_Status'].map(status_map)\n",
    "\n",
    "# Drop rows with NaN target (if any)\n",
    "train_data = train_data[train_data['Customer_Status'].isin([0,1])]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cols_to_drop = ['Customer_ID', 'Churn_Category', 'Churn_Reason']\n",
    "train_data = train_data.drop(columns=[col for col in cols_to_drop if col in train_data.columns])\n",
    "\n",
    "# Handle missing numeric values\n",
    "num_cols = train_data.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    train_data[col] = train_data[col].fillna(train_data[col].median())\n",
    "\n",
    "# Handle missing categorical values\n",
    "cat_cols = train_data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    train_data[col] = train_data[col].fillna(train_data[col].mode()[0])\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Split features and target\n",
    "X = train_data.drop('Customer_Status', axis=1)\n",
    "y = train_data['Customer_Status']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "566218be-f0a6-43d1-8c3c-8dbb18845d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Evaluation:\n",
      "Accuracy: 0.8099688473520249\n",
      "Confusion Matrix:\n",
      " [[860 105]\n",
      " [139 180]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       965\n",
      "           1       0.63      0.56      0.60       319\n",
      "\n",
      "    accuracy                           0.81      1284\n",
      "   macro avg       0.75      0.73      0.74      1284\n",
      "weighted avg       0.80      0.81      0.81      1284\n",
      "\n",
      "\n",
      "Random Forest Evaluation:\n",
      "Accuracy: 0.8348909657320872\n",
      "Confusion Matrix:\n",
      " [[903  62]\n",
      " [150 169]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.89       965\n",
      "           1       0.73      0.53      0.61       319\n",
      "\n",
      "    accuracy                           0.83      1284\n",
      "   macro avg       0.79      0.73      0.75      1284\n",
      "weighted avg       0.83      0.83      0.83      1284\n",
      "\n",
      "\n",
      "SVM Evaluation:\n",
      "Accuracy: 0.8200934579439252\n",
      "Confusion Matrix:\n",
      " [[869  96]\n",
      " [135 184]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       965\n",
      "           1       0.66      0.58      0.61       319\n",
      "\n",
      "    accuracy                           0.82      1284\n",
      "   macro avg       0.76      0.74      0.75      1284\n",
      "weighted avg       0.81      0.82      0.82      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Train Models\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df9e0ea5-f6e9-4ba7-88de-cac20938eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Prediction Data\n",
    "\n",
    "predict_data = pd.read_csv(\"Predicting_Data.csv\")\n",
    "original_data = predict_data.copy()  # Keep original for output\n",
    "\n",
    "# Drop unnecessary columns\n",
    "predict_data = predict_data.drop(columns=[col for col in cols_to_drop if col in predict_data.columns], errors='ignore')\n",
    "\n",
    "# Keep only columns present in training\n",
    "common_cols = [col for col in X.columns if col in predict_data.columns]\n",
    "predict_data = predict_data[common_cols]\n",
    "\n",
    "# Handle missing numeric values\n",
    "num_cols = predict_data.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    predict_data[col] = predict_data[col].fillna(X[col].median())\n",
    "\n",
    "# Handle categorical variables\n",
    "cat_cols = predict_data.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    if col in label_encoders:\n",
    "        le = label_encoders[col]\n",
    "        most_freq_class = le.classes_[0]\n",
    "        predict_data[col] = predict_data[col].apply(lambda x: x if x in le.classes_ else most_freq_class)\n",
    "        predict_data[col] = le.transform(predict_data[col])\n",
    "\n",
    "# Scale prediction data\n",
    "predict_data_scaled = scaler.transform(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33a9dd7d-cfa7-4fd1-9158-ab70500fd128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved successfully \n"
     ]
    }
   ],
   "source": [
    "# 4. Make Predictions\n",
    "\n",
    "for name, model in models.items():\n",
    "    original_data[f'Customer_Status_Predicted_{name}'] = model.predict(predict_data_scaled)\n",
    "\n",
    "\n",
    "# 5. Save Predictions\n",
    "\n",
    "original_data.to_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\DATA_SCIENCE_PROJECT\\Telecom Customer Churn Prediction\\Predictions.csv\", index=False)\n",
    "print(\"Predictions saved successfully \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a58d7-6a4e-40a3-9891-6e378af08c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
